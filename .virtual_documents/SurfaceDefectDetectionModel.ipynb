


#Importing Libraries
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten
from sklearn.datasets import load_files
from tensorflow.python.keras.utils import np_utils


train_dir = 'NEU Metal Surface Defects Data/train'
val_dir = 'NEU Metal Surface Defects Data/valid'
test_dir='NEU Metal Surface Defects Data/test'
print("Path: ",os.listdir("NEU Metal Surface Defects Data"))
print("Train: ",os.listdir("NEU Metal Surface Defects Data/train"))
print("Test: ",os.listdir("NEU Metal Surface Defects Data/test"))
print("Validation: ",os.listdir("NEU Metal Surface Defects Data/valid"))





# print("Inclusion Defect")
# print("Training Images:",len(os.listdir(train_dir+'/'+'Inclusion')))
# print("Testing Images:",len(os.listdir(test_dir+'/'+'Inclusion')))
# print("Validation Images:",len(os.listdir(val_dir+'/'+'Inclusion')))

dirs = os.listdir(train_dir)
train_images = 0;
val_images = 0;
test_images = 0;
for dir in dirs:
    print(dir+" Defects->")
    print("Training Images:", len(os.listdir(train_dir+'/'+dir)))
    train_images += len(os.listdir(train_dir+'/'+dir))
    print("Validation Images:", len(os.listdir(val_dir+'/'+dir)))
    val_images += len(os.listdir(val_dir+'/'+dir))
    print("Testing Images:", len(os.listdir(test_dir+'/'+dir)))
    test_images += len(os.listdir(test_dir+'/'+dir))

print("Total Training set images: ", train_images)
print("Total Validation set images: ", val_images)
print("Total Testing set images: ", test_images)





img_size = 180
batch = 32

train_ds = tf.keras.utils.image_dataset_from_directory(train_dir,
                                                       seed=123,
                                                       batch_size=batch,
                                                       image_size=(img_size, img_size))

val_ds = tf.keras.utils.image_dataset_from_directory(val_dir,
                                                       seed=123,
                                                       batch_size=batch,
                                                       image_size=(img_size, img_size))


defect_name = train_ds.class_names
defect_name


import matplotlib.pyplot as plt
import seaborn as sns


plt.figure(figsize=(10, 10))

i = 0
for images, labels in train_ds.take(1):
    for i in range(9):
        plt.subplot(3, 3, i+1)
        plt.imshow(images[i].numpy().astype('uint8'))
        plt.title(defect_name[labels[i]])
        plt.axis('off')


AUTOTUNE = tf.data.AUTOTUNE


train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)


val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)


#Data Augmentation

data_augmentation = Sequential([
    layers.RandomFlip("horizontal", input_shape = (img_size,img_size,3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1)
])


i = 0
plt.figure(figsize=(10, 10))

for images, labels in train_ds.take(1):
    for i in range(9):
        images = data_augmentation(images)
        plt.subplot(3, 3, i+1)
        plt.imshow(images[0].numpy().astype('uint8'))
        plt.axis('off')





#Model Creation

model = Sequential([
    data_augmentation,
    layers.Rescaling(1./255),
    Conv2D(16, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(32, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(64, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Dropout(0.2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(6)
])
model.summary()





model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])


tf.keras.utils.plot_model(
    model,
    to_file='cnn_architecture.png',
    show_shapes=True)


history = model.fit(train_ds, epochs=15, validation_data=val_ds)





#Checking the prediction capability
# input_image = tf.keras.utils.load_img("NEU Metal Surface Defects Data/test/Rolled/RS_1.bmp", target_size=(180,180))
# input_image_array = tf.keras.utils.img_to_array(input_image)
# input_image_exp_dim = tf.expand_dims(input_image_array,0)

# predictions = model.predict(input_image_exp_dim)
# result = tf.nn.softmax(predictions[0])
# defect_name[np.argmax(result)]

def classify_defect(image_path):
    input_image = tf.keras.utils.load_img(image_path, target_size=(180,180))
    input_image_array = tf.keras.utils.img_to_array(input_image)
    input_image_exp_dim = tf.expand_dims(input_image_array,0)

    predictions = model.predict(input_image_exp_dim)
    result = tf.nn.softmax(predictions[0])
    outcome = 'The Image is of ' + defect_name[np.argmax(result)] + ' defect with a score of '+ str(np.max(result)*100)
    return outcome


classify_defect('NEU Metal Surface Defects Data/test/Patches/Pa_101.bmp')


model.save('Surface_Defect_Detection_Model.h5')





sns.set_style("whitegrid")
plt.subplot(211)  
plt.plot(history.history['accuracy'])  
plt.plot(history.history['val_accuracy'])  
plt.title('model accuracy')  
plt.ylabel('accuracy')  
plt.xlabel('epoch')  
plt.legend(['train', 'test'], loc='upper left')
plt.show()


sns.set_style("whitegrid")
plt.subplot(212)  
plt.plot(history.history['loss'])  
plt.plot(history.history['val_loss'])  
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')  
plt.show()






